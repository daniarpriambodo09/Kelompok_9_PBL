{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bccf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0129fce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('forecasting_jawa_timur_Kab. Kediri',), ('forecasting_jawa_timur_Kab. Malang',), ('forecasting_jawa_timur_Kab. Banyuwangi',), ('forecasting_jawa_timur_Kab. Pasuruan',), ('forecasting_jawa_timur_Kab. Sidoarjo',), ('forecasting_jawa_timur_Kab. Nganjuk',), ('Jawa Timur_Kab. Kediri',), ('Jawa Timur_Kab. Malang',), ('Jawa Timur_Kab. Banyuwangi',), ('Jawa Timur_Kab. Pasuruan',), ('Jawa Timur_Kab. Sidoarjo',), ('Jawa Timur_Kab. Nganjuk',), ('Jawa Timur_Kab. Tuban',), ('Jawa Timur_Kab. Gresik',), ('Jawa Timur_Kab. Sumenep',), ('Jawa Timur_Kota Surabaya',), ('forecasting_jawa_timur_Kab. Tuban',), ('forecasting_jawa_timur_Kab. Gresik',), ('forecasting_jawa_timur_Kab. Sumenep',), ('forecasting_jawa_timur_Kota Surabaya',)]\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host = \"localhost\",\n",
    "    database = \"weather_forecasting\",\n",
    "    user = \"postgres\",\n",
    "    password = \"12345678\"\n",
    ")\n",
    "\n",
    "DATABASE_URL = \"postgresql://postgres:12345678@localhost:5432/weather_forecasting\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "excluded_tables = (\"Tabel Cuaca\", \"Tabel_Kota\")\n",
    "cur.execute(\"\"\"\n",
    "            SELECT tablename\n",
    "            FROM pg_tables\n",
    "            WHERE schemaname = 'public'\n",
    "            AND tablename NOT IN %s;\n",
    "\"\"\", (excluded_tables,))\n",
    "\n",
    "tables = cur.fetchall()\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abff09ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "compass_to_degrees = {\n",
    "    \"N\": 0, \"NNE\": 22.5, \"NE\": 45, \"ENE\": 67.5,\n",
    "    \"E\": 90, \"ESE\": 112.5, \"SE\": 135, \"SSE\": 157.5,\n",
    "    \"S\": 180, \"SSW\": 202.5, \"SW\": 225, \"WSW\": 247.5,\n",
    "    \"W\": 270, \"WNW\": 292.5, \"NW\": 315, \"NNW\": 337.5,\n",
    "    \"C\": 0\n",
    "}\n",
    "def direction_to_sin_cos(direction):\n",
    "    if pd.isna(direction) or direction not in compass_to_degrees:\n",
    "        return np.nan, np.nan\n",
    "    degree = compass_to_degrees[direction]\n",
    "    rad = np.deg2rad(degree)\n",
    "    return np.sin(rad), np.cos(rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac1eca43",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 108\u001b[39m\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# Cari best ARIMA order\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m best_order = \u001b[43mfind_best_arima_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m best_order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    110\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not find a suitable ARIMA order for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Using default (1,1,1).\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 72\u001b[39m, in \u001b[36mfind_best_arima_order\u001b[39m\u001b[34m(series, p_range, d_range, q_range)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     71\u001b[39m     model = ARIMA(series, order=(p,d,q))\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m results.aic < best_aic:\n\u001b[32m     74\u001b[39m         best_aic = results.aic\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Vs_Code/Kuliah/Semester 4/daily_venv/lib/python3.12/site-packages/statsmodels/tsa/arima/model.py:395\u001b[39m, in \u001b[36mARIMA.fit\u001b[39m\u001b[34m(self, start_params, transformed, includes_fixed, method, method_kwargs, gls, gls_kwargs, cov_type, cov_kwds, return_params, low_memory)\u001b[39m\n\u001b[32m    392\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    393\u001b[39m     method_kwargs.setdefault(\u001b[33m'\u001b[39m\u001b[33mdisp\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m     res = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcov_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcov_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_kwds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcov_kwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmethod_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_params:\n\u001b[32m    399\u001b[39m         res.fit_details = res.mlefit\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Vs_Code/Kuliah/Semester 4/daily_venv/lib/python3.12/site-packages/statsmodels/tsa/statespace/mlemodel.py:705\u001b[39m, in \u001b[36mMLEModel.fit\u001b[39m\u001b[34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[39m\n\u001b[32m    703\u001b[39m         flags[\u001b[33m'\u001b[39m\u001b[33mhessian_method\u001b[39m\u001b[33m'\u001b[39m] = optim_hessian\n\u001b[32m    704\u001b[39m     fargs = (flags,)\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m     mlefit = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m                         \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m                         \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m                         \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m                         \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m                         \u001b[49m\u001b[43mskip_hessian\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[38;5;66;03m# Just return the fitted parameters if requested\u001b[39;00m\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_params:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Vs_Code/Kuliah/Semester 4/daily_venv/lib/python3.12/site-packages/statsmodels/base/model.py:566\u001b[39m, in \u001b[36mLikelihoodModel.fit\u001b[39m\u001b[34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[39m\n\u001b[32m    563\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_t\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    565\u001b[39m optimizer = Optimizer()\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m xopt, retvals, optim_settings = \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mhessian\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mretall\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[38;5;66;03m# Restore cov_type, cov_kwds and use_t\u001b[39;00m\n\u001b[32m    576\u001b[39m optim_settings.update(kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Vs_Code/Kuliah/Semester 4/daily_venv/lib/python3.12/site-packages/statsmodels/base/optimizer.py:243\u001b[39m, in \u001b[36mOptimizer._fit\u001b[39m\u001b[34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[39m\n\u001b[32m    240\u001b[39m     fit_funcs.update(extra_fit_funcs)\n\u001b[32m    242\u001b[39m func = fit_funcs[method]\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m xopt, retvals = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mretall\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhessian\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m optim_settings = {\u001b[33m'\u001b[39m\u001b[33moptimizer\u001b[39m\u001b[33m'\u001b[39m: method, \u001b[33m'\u001b[39m\u001b[33mstart_params\u001b[39m\u001b[33m'\u001b[39m: start_params,\n\u001b[32m    249\u001b[39m                   \u001b[33m'\u001b[39m\u001b[33mmaxiter\u001b[39m\u001b[33m'\u001b[39m: maxiter, \u001b[33m'\u001b[39m\u001b[33mfull_output\u001b[39m\u001b[33m'\u001b[39m: full_output,\n\u001b[32m    250\u001b[39m                   \u001b[33m'\u001b[39m\u001b[33mdisp\u001b[39m\u001b[33m'\u001b[39m: disp, \u001b[33m'\u001b[39m\u001b[33mfargs\u001b[39m\u001b[33m'\u001b[39m: fargs, \u001b[33m'\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m'\u001b[39m: callback,\n\u001b[32m    251\u001b[39m                   \u001b[33m'\u001b[39m\u001b[33mretall\u001b[39m\u001b[33m'\u001b[39m: retall, \u001b[33m\"\u001b[39m\u001b[33mextra_fit_funcs\u001b[39m\u001b[33m\"\u001b[39m: extra_fit_funcs}\n\u001b[32m    252\u001b[39m optim_settings.update(kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Vs_Code/Kuliah/Semester 4/daily_venv/lib/python3.12/site-packages/statsmodels/base/optimizer.py:660\u001b[39m, in \u001b[36m_fit_lbfgs\u001b[39m\u001b[34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[39m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m approx_grad:\n\u001b[32m    658\u001b[39m     func = f\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m retvals = \u001b[43moptimize\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfmin_l_bfgs_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m full_output:\n\u001b[32m    666\u001b[39m     xopt, fopt, d = retvals\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Vs_Code/Kuliah/Semester 4/daily_venv/lib/python3.12/site-packages/scipy/optimize/_lbfgsb_py.py:277\u001b[39m, in \u001b[36mfmin_l_bfgs_b\u001b[39m\u001b[34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[39m\n\u001b[32m    267\u001b[39m callback = _wrap_callback(callback)\n\u001b[32m    268\u001b[39m opts = {\u001b[33m'\u001b[39m\u001b[33mmaxcor\u001b[39m\u001b[33m'\u001b[39m: m,\n\u001b[32m    269\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mftol\u001b[39m\u001b[33m'\u001b[39m: factr * np.finfo(\u001b[38;5;28mfloat\u001b[39m).eps,\n\u001b[32m    270\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mgtol\u001b[39m\u001b[33m'\u001b[39m: pgtol,\n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m'\u001b[39m: callback,\n\u001b[32m    275\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmaxls\u001b[39m\u001b[33m'\u001b[39m: maxls}\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m res = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m                       \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m d = {\u001b[33m'\u001b[39m\u001b[33mgrad\u001b[39m\u001b[33m'\u001b[39m: res[\u001b[33m'\u001b[39m\u001b[33mjac\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    280\u001b[39m      \u001b[33m'\u001b[39m\u001b[33mtask\u001b[39m\u001b[33m'\u001b[39m: res[\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    281\u001b[39m      \u001b[33m'\u001b[39m\u001b[33mfuncalls\u001b[39m\u001b[33m'\u001b[39m: res[\u001b[33m'\u001b[39m\u001b[33mnfev\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    282\u001b[39m      \u001b[33m'\u001b[39m\u001b[33mnit\u001b[39m\u001b[33m'\u001b[39m: res[\u001b[33m'\u001b[39m\u001b[33mnit\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    283\u001b[39m      \u001b[33m'\u001b[39m\u001b[33mwarnflag\u001b[39m\u001b[33m'\u001b[39m: res[\u001b[33m'\u001b[39m\u001b[33mstatus\u001b[39m\u001b[33m'\u001b[39m]}\n\u001b[32m    284\u001b[39m f = res[\u001b[33m'\u001b[39m\u001b[33mfun\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Vs_Code/Kuliah/Semester 4/daily_venv/lib/python3.12/site-packages/scipy/optimize/_lbfgsb_py.py:441\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[39m\n\u001b[32m    433\u001b[39m _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[32m    434\u001b[39m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m3\u001b[39m:\n\u001b[32m    437\u001b[39m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[32m    438\u001b[39m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[32m    439\u001b[39m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[32m    440\u001b[39m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m441\u001b[39m     f, g = \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m1\u001b[39m:\n\u001b[32m    443\u001b[39m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[32m    444\u001b[39m     n_iterations += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Vs_Code/Kuliah/Semester 4/daily_venv/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:342\u001b[39m, in \u001b[36mScalarFunction.fun_and_grad\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfun_and_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    343\u001b[39m         \u001b[38;5;28mself\u001b[39m._update_x(x)\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_fun()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Vs_Code/Kuliah/Semester 4/daily_venv/lib/python3.12/site-packages/numpy/_core/numeric.py:2470\u001b[39m, in \u001b[36m_array_equal_dispatcher\u001b[39m\u001b[34m(a1, a2, equal_nan)\u001b[39m\n\u001b[32m   2465\u001b[39m             result |= isnan(x) & isnan(y)\n\u001b[32m   2467\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result[()]  \u001b[38;5;66;03m# Flatten 0d arrays to scalars\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2470\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_array_equal_dispatcher\u001b[39m(a1, a2, equal_nan=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   2471\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (a1, a2)\n\u001b[32m   2474\u001b[39m _no_nan_types = {\n\u001b[32m   2475\u001b[39m     \u001b[38;5;66;03m# should use np.dtype.BoolDType, but as of writing\u001b[39;00m\n\u001b[32m   2476\u001b[39m     \u001b[38;5;66;03m# that fails the reloading test.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2481\u001b[39m     \u001b[38;5;28mtype\u001b[39m(dtype(nt.int64)),\n\u001b[32m   2482\u001b[39m }\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "\n",
    "for table_name_tuple in tables:\n",
    "    table_name = table_name_tuple[0]\n",
    "    \n",
    "    if 'forecast' not in table_name:\n",
    "        data_cuaca = pd.read_sql(f'SELECT * FROM \"{table_name}\"', engine)\n",
    "        id_city = data_cuaca[\"Id_City\"].unique().tolist()[0]\n",
    "        kota = data_cuaca[\"Kota\"].unique().tolist()[0]\n",
    "\n",
    "        data_cuaca[\"TANGGAL\"] = pd.to_datetime(data_cuaca[\"TANGGAL\"])\n",
    "        data_cuaca = data_cuaca.set_index(\"TANGGAL\")\n",
    "\n",
    "\n",
    "        features_to_predict_original = ['TN', 'TX', 'TAVG', 'RH_AVG','RR', 'SS']\n",
    "        all_relevant_columns = features_to_predict_original + ['DDD_CAR']\n",
    "\n",
    "        for col in features_to_predict_original:\n",
    "            if col in data_cuaca.columns:\n",
    "                data_cuaca[col] = pd.to_numeric(data_cuaca[col], errors='coerce')\n",
    "\n",
    "        compass_to_degrees = {\n",
    "            \"N\": 0, \"NNE\": 22.5, \"NE\": 45, \"ENE\": 67.5,\n",
    "            \"E\": 90, \"ESE\": 112.5, \"SE\": 135, \"SSE\": 157.5,\n",
    "            \"S\": 180, \"SSW\": 202.5, \"SW\": 225, \"WSW\": 247.5,\n",
    "            \"W\": 270, \"WNW\": 292.5, \"NW\": 315, \"NNW\": 337.5,\n",
    "            \"C\": 0\n",
    "        }\n",
    "\n",
    "        def direction_to_sin_cos(direction):\n",
    "            if pd.isna(direction) or direction not in compass_to_degrees:\n",
    "                return np.nan, np.nan\n",
    "            degree = compass_to_degrees[direction]\n",
    "            rad = np.deg2rad(degree)\n",
    "            return np.sin(rad), np.cos(rad)\n",
    "\n",
    "        if 'DDD_CAR' in data_cuaca.columns:\n",
    "            data_cuaca['DDD_CAR'] = data_cuaca['DDD_CAR'].astype(str).str.strip().str.upper()\n",
    "            data_cuaca['WindDir_sin'], data_cuaca['WindDir_cos'] = zip(*data_cuaca['DDD_CAR'].map(direction_to_sin_cos))\n",
    "            data_cuaca = data_cuaca.drop(columns=['DDD_CAR'])\n",
    "        else:\n",
    "            print(\"\\nDDD_CAR column not found. Skipping wind direction encoding.\")\n",
    "        \n",
    "\n",
    "        features_for_modeling = features_to_predict_original[:] # Create a copy\n",
    "        if 'WindDir_sin' in data_cuaca.columns: \n",
    "            features_for_modeling.extend(['WindDir_sin', 'WindDir_cos'])\n",
    "\n",
    "        for col in features_for_modeling:\n",
    "            if col in data_cuaca.columns:\n",
    "                # Using linear interpolation for numeric columns\n",
    "                data_cuaca[col] = data_cuaca[col].interpolate(method='linear')\n",
    "                # Fill any remaining NaNs at the beginning or end\n",
    "                data_cuaca[col] = data_cuaca[col].fillna(method='ffill').fillna(method='bfill')\n",
    "            else:\n",
    "                print(f\"Warning: Column {col} not found for NaN handling after encoding.\")\n",
    "\n",
    "        data_cuaca.dropna(subset=features_for_modeling, inplace=True)\n",
    "\n",
    "        def find_best_arima_order(series, p_range, d_range, q_range):\n",
    "            best_aic = np.inf\n",
    "            best_order = None\n",
    "            \n",
    "            if series.ndim > 1:\n",
    "                series = series.iloc[:,0]\n",
    "\n",
    "            for d in d_range:\n",
    "                for p in p_range:\n",
    "                    for q in q_range:\n",
    "                        try:\n",
    "                            model = ARIMA(series, order=(p,d,q))\n",
    "                            results = model.fit()\n",
    "                            if results.aic < best_aic:\n",
    "                                best_aic = results.aic\n",
    "                                best_order = (p,d,q)\n",
    "                        except Exception as e:\n",
    "                            continue\n",
    "            return best_order\n",
    "        \n",
    "        p_values = range(0, 4) \n",
    "        d_values = range(0, 2) \n",
    "        q_values = range(0, 4) \n",
    "\n",
    "        forecast_horizon = 21\n",
    "        rmse_scores = {}\n",
    "        future_forecasts_dict = {}\n",
    "\n",
    "        train_data_cuaca = data_cuaca.iloc[:-forecast_horizon]\n",
    "        test_data_cuaca = data_cuaca.iloc[-forecast_horizon:]\n",
    "\n",
    "        for feature in features_for_modeling:\n",
    "            if feature not in data_cuaca.columns or data_cuaca[feature].isnull().all():\n",
    "                print(f\"\\nSkipping feature '{feature}' due to missing data or column not found.\")\n",
    "                rmse_scores[feature] = np.nan\n",
    "                future_forecasts_dict[feature] = [np.nan] * forecast_horizon\n",
    "                continue\n",
    "            \n",
    "            series_train = train_data_cuaca[feature].astype(np.float64)\n",
    "            series_test = test_data_cuaca[feature].astype(np.float64)\n",
    "\n",
    "            if len(series_train) < (max(p_values) + max(d_values) + max(q_values) + 5) or len(series_train) < 10:\n",
    "                print(f\"Not enough data points for feature {feature} to reliably fit ARIMA. Skipping.\")\n",
    "                rmse_scores[feature] = np.nan\n",
    "                future_forecasts_dict[feature] = [np.nan] * forecast_horizon\n",
    "                continue\n",
    "\n",
    "            # Cari best ARIMA order\n",
    "            best_order = find_best_arima_order(series_train, p_values, d_values, q_values)\n",
    "            if best_order is None:\n",
    "                print(f\"Could not find a suitable ARIMA order for {feature}. Using default (1,1,1).\")\n",
    "                best_order = (1, 1, 1)\n",
    "\n",
    "            # Train on train set dan evaluasi dengan RMSE\n",
    "            try:\n",
    "                model_eval = ARIMA(series_train, order=best_order)\n",
    "                model_eval_fit = model_eval.fit()\n",
    "                predictions_test = model_eval_fit.forecast(steps=forecast_horizon)\n",
    "\n",
    "                if len(predictions_test) == len(series_test):\n",
    "                    rmse = np.sqrt(mean_squared_error(series_test, predictions_test))\n",
    "                    rmse_scores[feature] = rmse\n",
    "                else:\n",
    "                    print(f\"Warning: Length mismatch for {feature}. Test: {len(series_test)}, Pred: {len(predictions_test)}. Skipping RMSE.\")\n",
    "                    rmse_scores[feature] = np.nan\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error during evaluation model fitting or prediction for {feature}: {e}\")\n",
    "                rmse_scores[feature] = np.nan\n",
    "\n",
    "            # Retrain dengan full data dan forecast masa depan\n",
    "            full_series = data_cuaca[feature].astype(np.float64)\n",
    "            try:\n",
    "                model_future = ARIMA(full_series, order=best_order)\n",
    "                model_future_fit = model_future.fit()\n",
    "                future_forecast_values = model_future_fit.forecast(steps=forecast_horizon)\n",
    "                future_forecasts_dict[feature] = future_forecast_values\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error during final model fitting or future forecasting for {feature}: {e}\")\n",
    "                future_forecasts_dict[feature] = [np.nan] * forecast_horizon\n",
    "\n",
    "        last_date = data_cuaca.index[-1]\n",
    "        future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=forecast_horizon, freq='D')\n",
    "        forecast_data_cuaca = pd.DataFrame(index=future_dates)\n",
    "\n",
    "        print(\"\\n--- Forecasts for the Next 21 Days ---\")\n",
    "        if future_forecasts_dict:\n",
    "            for feature, forecasts in future_forecasts_dict.items():\n",
    "                # Ensure forecasts Series has the correct datetime index for alignment\n",
    "                forecast_series_with_dates = pd.Series(forecasts.values, index=future_dates)\n",
    "                forecast_data_cuaca[feature] = round(forecast_series_with_dates, 2)\n",
    "        else:\n",
    "            print(\"No forecasts were generated.\")\n",
    "\n",
    "        loaded_scaler = joblib.load('new_model_ks/scaler_cuaca.pkl')\n",
    "        loaded_model = joblib.load('new_model_ks/model_cuaca_rf.pkl')\n",
    "        loaded_features_order = joblib.load('new_model_ks/model_features.pkl')\n",
    "\n",
    "        forecast_data_cuaca.rename(columns={'WindDir_sin': 'WindGustDir_sin', 'WindDir_cos': 'WindGustDir_cos'}, inplace=True)\n",
    "\n",
    "        # Ensure column order matches the features used during training\n",
    "        forecast_data_cuaca_reordered = forecast_data_cuaca[loaded_features_order]\n",
    "\n",
    "        # Scale the forecast data using the loaded scaler\n",
    "        forecast_scaled = loaded_scaler.transform(forecast_data_cuaca_reordered)\n",
    "\n",
    "        # Predict probabilities on the scaled forecast data\n",
    "        y_proba_forecast = loaded_model.predict_proba(forecast_scaled)[:, 1]\n",
    "\n",
    "        # Apply custom threshold for classification\n",
    "        custom_threshold = 0.4\n",
    "        y_pred_forecast_custom = (y_proba_forecast >= custom_threshold).astype(int)\n",
    "\n",
    "        # Map numerical labels back to 'hujan' and 'cerah'\n",
    "        label_map_inverse = {1: 'Cerah', 0: 'Hujan'}\n",
    "        classified_forecast_labels = pd.Series(y_pred_forecast_custom).map(label_map_inverse)\n",
    "\n",
    "        # Create a DataFrame for the classified forecasts\n",
    "        classified_forecast_data_cuaca = pd.DataFrame({\n",
    "            'TN': forecast_data_cuaca['TN'],\n",
    "            'TX': forecast_data_cuaca['TX'],\n",
    "            'TAVG': forecast_data_cuaca['TAVG'],\n",
    "            'RH_AVG': forecast_data_cuaca['RH_AVG'],\n",
    "            'RR': forecast_data_cuaca['RR'],\n",
    "            'SS': forecast_data_cuaca['SS'],\n",
    "            'WindDir_sin': forecast_data_cuaca['WindGustDir_sin'],\n",
    "            'WindDir_cos': forecast_data_cuaca['WindGustDir_cos'],\n",
    "            'Cuaca': classified_forecast_labels.values\n",
    "        }, index=forecast_data_cuaca.index)\n",
    "\n",
    "        classified_forecast_data_cuaca = classified_forecast_data_cuaca.reset_index()\n",
    "        classified_forecast_data_cuaca = classified_forecast_data_cuaca.rename(columns={\"index\" : \"TANGGAL\"})\n",
    "\n",
    "        classified_forecast_data_cuaca[\"Id_Kota\"] = id_city\n",
    "        classified_forecast_data_cuaca[\"Kota\"] = kota\n",
    "        classified_forecast_data_cuaca = classified_forecast_data_cuaca[[\"TANGGAL\",\"Id_Kota\", \"Kota\", \"TN\", \"TX\", \"TAVG\", \"RH_AVG\", \"RR\", \"SS\",\"WindDir_sin\", \"WindDir_cos\", \"Cuaca\"]]\n",
    "\n",
    "        classified_forecast_data_cuaca.to_sql(f'forecasting_jawa_timur_{kota}', engine, index=False, if_exists=\"replace\")\n",
    "        print(f\"\\n{i}. {table_name}\")\n",
    "        display(classified_forecast_data_cuaca)\n",
    "\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a652a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # scaler = joblib.load(\"/home/daniar/Vs_Code/Kuliah/Semester 4/TWS/Coba coba/my_models/fix_scaler.pkl\") \n",
    "        # model = joblib.load(\"/home/daniar/Vs_Code/Kuliah/Semester 4/TWS/Coba coba/my_models/fix_model.pkl\")\n",
    "        \n",
    "        # forecast_data_cuaca = forecast_data_cuaca.rename(columns={\"WindDir_sin\" : \"WindGustDir_sin\", \"WindDir_cos\" : \"WindGustDir_cos\"})\n",
    "\n",
    "        # forecast_data_cuaca = forecast_data_cuaca.reset_index()\n",
    "        # forecast_data_cuaca = forecast_data_cuaca.rename(columns={\"index\" : \"TANGGAL\"})\n",
    "\n",
    "        # tanggal = forecast_data_cuaca[\"TANGGAL\"]\n",
    "        # forecast_data_cuaca = forecast_data_cuaca.drop(columns=\"TANGGAL\")\n",
    "\n",
    "        # forecast_data_cuaca = forecast_data_cuaca[['TN', 'TX', 'TAVG', 'RR', 'RH_AVG', 'SS', \"WindGustDir_sin\", \"WindGustDir_cos\"]]\n",
    "\n",
    "        # X_new_scaled = scaler.transform(forecast_data_cuaca)\n",
    "\n",
    "        # custom_threshold = 0.4\n",
    "        # y_proba_new = model.predict_proba(X_new_scaled)[:, 1]\n",
    "        # y_pred_new = (y_proba_new >= custom_threshold).astype(int)\n",
    "\n",
    "        # forecast_data_cuaca[\"RainTomorrow_Pred\"] = y_pred_new\n",
    "        # forecast_data_cuaca[\"RainTomorrow_Prob\"] = y_proba_new\n",
    "        # forecast_data_cuaca[\"RainTomorrow_Pred\"] = forecast_data_cuaca[\"RainTomorrow_Pred\"].map({0 : \"Cerah\", 1 : \"Hujan\"})\n",
    "\n",
    "        # forecast_data_cuaca[\"TANGGAL\"] = tanggal\n",
    "        # sort_columns = [\"TANGGAL\"] + [col for col in forecast_data_cuaca.columns if col != \"TANGGAL\"]\n",
    "\n",
    "        # forecast_data_cuaca = forecast_data_cuaca[sort_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a470fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a882c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"weather_forecasting\",\n",
    "    user=\"postgres\",\n",
    "    password=\"12345678\"\n",
    ")\n",
    "\n",
    "DATABASE_URL = \"postgresql://postgres:12345678@localhost:5432/weather_forecasting\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "excluded_tables = (\"Tabel Cuaca\", \"Tabel_Kota\")\n",
    "cur.execute(\"\"\"\n",
    "    SELECT tablename\n",
    "    FROM pg_tables\n",
    "    WHERE schemaname = 'public'\n",
    "    AND tablename NOT IN %s;\n",
    "\"\"\", (excluded_tables,))\n",
    "\n",
    "tables = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2926f39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_forecasting = []\n",
    "\n",
    "for table_name_tuple in tables:\n",
    "    nama_table = table_name_tuple[0]\n",
    "\n",
    "    if \"forecasting\" in nama_table:\n",
    "        df = pd.read_sql(f'SELECT * FROM \"{nama_table}\"', engine)\n",
    "        data_forecasting.append(df)\n",
    "\n",
    "merge_data = pd.concat(data_forecasting,ignore_index=True)\n",
    "merge_data.to_sql(\"forecasting_data_cuaca\", engine, index=False, if_exists=\"replace\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daily_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
